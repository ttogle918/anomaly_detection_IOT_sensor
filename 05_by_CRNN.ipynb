{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "046059fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d3091e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'E:/anomoly_detection_IOT_sensor/iotAnomaly_train/csv_files'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b0b096",
   "metadata": {},
   "source": [
    "# image 불러오기\n",
    "\n",
    "- numpy로 저장하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2155912",
   "metadata": {},
   "source": [
    "우선 이미지 파일 하나로 시도해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7488c4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = os.path.join(train_path, 'label_00006320620311.jpg')\n",
    "# img_path\n",
    "img = image.load_img(img_path)\n",
    "img_tensor = image.img_to_array(img)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206fdb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand a dimension (3D -> 4D)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "img_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7440540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling into [0, 1]\n",
    "img_tensor /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2cbb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10, 10) # set figure size\n",
    "plt.imshow(img_tensor[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d7b11b",
   "metadata": {},
   "source": [
    "### image 파일의 형태를 알아보자\n",
    "\n",
    "9개의 이미지 파일을 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51274dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size_v = 64\n",
    "target_size_h = 128\n",
    "def preprocess_img(img_path):\n",
    "    img = image.load_img(img_path, target_size=(target_size_v, target_size_h))\n",
    "    img_tensor = image.img_to_array(img)\n",
    "\n",
    "    # expand a dimension\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "\n",
    "    # scaling into [0, 1]\n",
    "    img_tensor /= 255.\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c25d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw plot ( 3 * 3 )\n",
    "# layout\n",
    "n_pic = 9\n",
    "n_col = 3\n",
    "n_row = 3\n",
    "\n",
    "margin = 3\n",
    "\n",
    "# blank matrix to store results\n",
    "total = np.zeros((n_row * target_size_v + (n_row - 1) * margin, n_col * target_size_h + (n_col - 1) * margin, 3))\n",
    "\n",
    "# append the image name\n",
    "img_seq = 0\n",
    "jpg_list = []\n",
    "# 9장만 저장 ( 미리보기 용도 )\n",
    "for (path, dir, files) in os.walk(train_path):\n",
    "    print(path)\n",
    "    for filename in files:\n",
    "        ext = os.path.splitext(filename)[-1]\n",
    "        if ext == '.jpg':\n",
    "            try :\n",
    "                jpg_list.append(filename)\n",
    "                img_seq += 1\n",
    "            except KeyError as e :\n",
    "                print(\"%s/%s\" % (path, filename))\n",
    "                break\n",
    "            if img_seq == 9 :\n",
    "                break\n",
    "\n",
    "img_seq = 0\n",
    "for i in range(n_row):\n",
    "    for j in range(n_col):\n",
    "        img_path = os.path.join(train_path, jpg_list[img_seq])\n",
    "        img_tensor = preprocess_img(img_path)\n",
    "\n",
    "        horizontal_start = i * target_size_v + i * margin\n",
    "\n",
    "        horizontal_end = horizontal_start + target_size_v\n",
    "\n",
    "        vertical_start = j * target_size_h + j * margin\n",
    "\n",
    "        vertical_end = vertical_start + target_size_h\n",
    "        total[horizontal_start : horizontal_end, vertical_start : vertical_end, :] = img_tensor[0]\n",
    "        img_seq += 1\n",
    "        \n",
    "img_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb73ddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the pictures in grid\n",
    "plt.figure(figsize=(32, 32))\n",
    "plt.imshow(total)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb94f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_tensor.shape)\n",
    "print(total.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71419213",
   "metadata": {},
   "source": [
    "### train 데이터셋에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6414872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu 메모리 증가를 허용하기 위해서 텐서나 연산 앞에 입력\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "    # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "        print(e)\n",
    "\n",
    "X = []\n",
    "for (path, dir, files) in os.walk(train_path):\n",
    "    for filename in files:\n",
    "        ext = os.path.splitext(filename)[-1]\n",
    "        if ext == '.jpg':\n",
    "            try :\n",
    "                X.extend(preprocess_img(os.path.join(train_path, filename)))\n",
    "            except KeyError as e :\n",
    "                print(\"%s/%s\" % (path, filename))\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d33c192c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23974, 64, 128, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(X[0]), len(X[0][0]), len(X[0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000660f9",
   "metadata": {},
   "source": [
    "X = []\n",
    "for (path, dir, files) in os.walk(train_path):\n",
    "    print(path)\n",
    "    for filename in files:\n",
    "        ext = os.path.splitext(filename)[-1]\n",
    "        if ext == '.jpg':\n",
    "            try :\n",
    "                img_path = os.path.join(train_path, filename)\n",
    "                X.extend(preprocess_img(img_path))                    \n",
    "            except KeyError as e :\n",
    "                print(\"%s/%s\" % (path, filename))\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "218d50ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 128, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "input_shape = (X.shape[1], X.shape[2], 3)\n",
    "\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c022c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 그림 출력 ( 확인 )\n",
    "plt.imshow(X[1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9165ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit에서 validation 나누기\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, np.array([0]*len(X)), test_size=0.2) # spt로 ins 추측\n",
    "\n",
    "# X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d55888b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5094"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 안쓰는 변수 삭제 ( 메모리 지우기)\n",
    "import gc\n",
    "gc.collect()\n",
    "# del X\n",
    "# del jpg_list\n",
    "# del img\n",
    "# del total\n",
    "# del img_path\n",
    "# del img_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea22001b",
   "metadata": {},
   "source": [
    "## Model 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2749098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "# from keras.callbacks import EarlyStopping\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.layers import Dense, MaxPooling2D, Conv2D, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bad7bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1_64 (Conv2D)           (None, 64, 128, 128)      3584      \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 16, 32, 128)       0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 512, 128)          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 32)                2080      \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,105\n",
      "Trainable params: 55,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu', input_shape=input_shape, name='conv1_64'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(4,4), name='pool1', padding='valid'))\n",
    "\n",
    "model.add(Reshape((-1,128)))\n",
    "          \n",
    "          \n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(32, name='dense1', activation='linear'))\n",
    "model.add(Dense(1, name='dense2', activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c076cc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "282/282 [==============================] - 36s 113ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.3749e-06 - val_accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "282/282 [==============================] - 34s 119ms/step - loss: 1.3082e-06 - accuracy: 1.0000 - val_loss: 7.8264e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "282/282 [==============================] - 34s 119ms/step - loss: 5.9835e-07 - accuracy: 1.0000 - val_loss: 4.7359e-07 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# from keras.models import load_model\n",
    "\n",
    "# class save(keras.callbacks.Callback):\n",
    "#     def __init__(self, model):\n",
    "#         self.count = 0\n",
    "#         self.model = model\n",
    "\n",
    "#     def on_epoch_end(self, bath, logs={}):\n",
    "#         self.count = self.count + 1\n",
    "#         if self.count % 10 == 0:\n",
    "#             model.save(\"mymodel_epoch_{}.h5\".format(self.count))\n",
    "        \n",
    "# s = save(model)\n",
    "# es = EarlyStopping(monitor='val_loss', patience=5)\n",
    "# mc = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# gpu 메모리 증가를 허용하기 위해서 텐서나 연산 앞에 입력\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "    # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "        print(e)\n",
    "# # 메모리 부족\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# with strategy.scope():\n",
    "history = model.fit(X[:10000], np.array([0]*10000), epochs=3, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae220bf",
   "metadata": {},
   "source": [
    "## test case를 통해 이상치 탐지\n",
    "\n",
    "train data에 대부분이 정상 데이터라는 가정하에 모두 정상 label값을 가지고 훈련하였다.\n",
    "\n",
    "test data까지 하면 메모리가 넘쳐서 다운될까봐 코드를 모델 훈련 이후에 넣었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29b66606",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'E:/anomoly_detection_IOT_sensor/iotAnomaly_test/csv_files'\n",
    "# gpu 메모리 증가를 허용하기 위해서 텐서나 연산 앞에 입력\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "    # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "        print(e)\n",
    "\n",
    "X = []\n",
    "for (path, dir, files) in os.walk(test_path):\n",
    "    for filename in files:\n",
    "        ext = os.path.splitext(filename)[-1]\n",
    "        if ext == '.jpg':\n",
    "            try :\n",
    "                X.extend(preprocess_img(os.path.join(test_path, filename)))\n",
    "            except KeyError as e :\n",
    "                print(\"%s/%s\" % (path, filename))\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1165405",
   "metadata": {},
   "source": [
    "os.putenv('TF_GPU_ALLOCATOR', 'cuda_malloc_async')\n",
    " https://www.tensorflow.org/guide/gpu\n",
    " InternalError: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4236c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "544edceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0c3de9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8744, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred), len(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dcb1951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3199"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9cc67ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"pickle/CRNN_ypred.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(y_pred, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f1f245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b7a658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_jupyter",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
